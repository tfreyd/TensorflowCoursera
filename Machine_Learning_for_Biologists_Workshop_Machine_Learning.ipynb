{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning for Biologists Workshop - Machine Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tfreyd/TensorflowCoursera/blob/main/Machine_Learning_for_Biologists_Workshop_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrGwy_7XfRss"
      },
      "source": [
        "# Introduction\n",
        "In the previous session, we showed you how to build a dataset containing images of colon polyps and corresponding image masks. This session will use an extended version of this dataset to build a machine learning pipeline to automatically segment colon polyps in images collected from real-world colonoscopies.\n",
        "\n",
        "The dataset we will be using is Kvasir-SEG, which contains 1,000 images with colon polyps collected from colonoscopies held at Bærum Hospital. There is no need to redownload the dataset as it will be done automatically through this notebook. Parts of this notebook was inspired by the tutorial provided by the official keras team at https://keras.io/examples/vision/oxford_pets_image_segmentation.\n",
        "\n",
        "The machine learning pipeline will mainly consist of the three following steps:\n",
        "\n",
        "1. Data preparation and loading.\n",
        "2. Model development and training.\n",
        "3. Model evaluation and testing.\n",
        "\n",
        "Each step is equally important in the development of any machine learning-based system. Before we start implementing the pipeline, let's start with preparing the environment with some initial setup.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIB9PoQuxBDz"
      },
      "source": [
        "# Setup\n",
        "First, we import the external modules and defines some functions that will help us with the implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbWfqKkdYg3C"
      },
      "source": [
        "## Import Modules\n",
        "Here, we download and import the modules we will be using to implement our machine learning pipeline. The pipeline will be implemented using [Tensorflow](https://www.tensorflow.org), which is a machine learning library developed by Google and is currently the most widely used tool available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShOQmC6TxDki"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z46WAXHz_Fh-"
      },
      "source": [
        "## Helper Functions\n",
        "We define a helper function that will aid us in showing images directly in this notebook. This is purely used for visualization and is not part of developing the machine learning pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqrmg2Mr8DNm"
      },
      "source": [
        "def show_images(images, figsize=(10,10), columns=2):\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i, image in enumerate(images):\n",
        "        plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKmwc4RbxSby"
      },
      "source": [
        "# Dataset Preparation and Loading\n",
        "In order to build a machine learning model that can automatically segment polyps in endoscopy images, we need data it can learn from. For the model to learn from data, the data must first be loaded into a format that the model can understand. Furthermore, we also want to organize the data to use one part for training and one part for testing after training has finished. This section covers the data preparation step of developing a machine learning pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GDi05_jxNdK"
      },
      "source": [
        "## Download the Dataset\n",
        "We start by downloading the dataset from the website and extracting the contents. We assign some variables that point to the location of the dataset so that in the future, we only need to change this in one place."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmkkE1VxzP2-"
      },
      "source": [
        "DATASET_URL = \"https://datasets.simula.no/kvasir-seg/Kvasir-SEG.zip\"\n",
        "DATASET_ZIP_PATH = os.path.join(os.path.abspath(os.sep), \"content\", \"Kvasir-SEG.zip\")\n",
        "DATASET_DIR_PATH = os.path.join(os.path.abspath(os.sep), \"content\", \"Kvasir-SEG\")\n",
        "\n",
        "if not os.path.exists(DATASET_ZIP_PATH):\n",
        "    !wget $DATASET_URL\n",
        "    !unzip $DATASET_ZIP_PATH &> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEnjrcPovusM"
      },
      "source": [
        "With the dataset downloaded and extracted, let's visualize a couple of image and mask pairs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrARtlNOuuDW"
      },
      "source": [
        "list_of_example_images = [\n",
        "    \"cju32srle1xfq083575i3fl75.jpg\",\n",
        "    \"cju33belnbyhm0878yxl42233.jpg\",\n",
        "    \"cju5vbo6jldrt0871jf6f1700.jpg\"\n",
        "]\n",
        "\n",
        "for filename in list_of_example_images:\n",
        "    example_image = load_img(os.path.join(DATASET_DIR_PATH, \"images\", filename))\n",
        "    example_mask = load_img(os.path.join(DATASET_DIR_PATH, \"masks\", filename))\n",
        "    show_images([example_image, example_mask])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lymmp38bvzlf"
      },
      "source": [
        "## Prepare the data\n",
        "Currently, the images are only stored on disk and not available in our Python program. For the model to process the images, we must first load them into memory. We do this by first getting a list of the location of all image and mask pairs so that we can more easily organize them later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYVXez4dxoBx"
      },
      "source": [
        "x_paths = []\n",
        "y_paths = []\n",
        "\n",
        "list_of_filenames = os.listdir(os.path.join(DATASET_DIR_PATH, \"images\"))\n",
        "\n",
        "for filename in list_of_filenames:\n",
        "    x_paths.append(os.path.join(DATASET_DIR_PATH, \"images\", filename))\n",
        "    y_paths.append(os.path.join(DATASET_DIR_PATH, \"masks\", filename))\n",
        "\n",
        "assert len(x_paths) == len(y_paths) \n",
        "\n",
        "print(\"number of image paths: %i\" % len(x_paths))\n",
        "print(\"number of mask paths: %i\" % len(y_paths))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pbNdaAGycRj"
      },
      "source": [
        "Now that we have all the file paths, we will organize them into three separate partitions; training, validation, and testing. The three partitions will be used as follows.\n",
        "\n",
        "* **Training Part** The training partition will be used to train the model.\n",
        "* **Validation Part** The training partition will be used to test the model during training. We use the validation part to verify that the model is learning something from the training dataset.\n",
        "* **Testing Part** The testing partition will be used to test the model after training. This is the only partition that the model does not see during training.\n",
        "\n",
        "We will split the data between a development dataset (80%) and a testing dataset (20%) in the following code example. The development dataset is further split into a training dataset (70%) and a validation dataset (30%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s547_Tf5y_Z0"
      },
      "source": [
        "x_development, x_test, y_development, y_test = train_test_split(x_paths, y_paths, test_size=0.20, random_state=0)\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_development, y_development, test_size=0.30, random_state=0)\n",
        "\n",
        "assert len(x_train) == len(y_train)\n",
        "assert len(x_train) == len(y_train)\n",
        "assert len(x_valid) == len(y_valid)\n",
        "assert len(x_test) == len(y_test)\n",
        "\n",
        "print(\"Number of training samples: %i\" % len(x_train))\n",
        "print(\"Number of validation samples: %i\" % len(x_valid))\n",
        "print(\"Number of testing samples: %i\" % len(x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5TLRx0o0vOx"
      },
      "source": [
        "With the image paths organized into their respective datasets, we now create the function responsible for loading the images into memory. Note that the function is complicated as it loads images in batches, which will be described later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJIIr1rr0vYG"
      },
      "source": [
        "class KvasirSEGDataLoader(keras.utils.Sequence):\n",
        "    def __init__(self, batch_size, image_size, image_paths, mask_paths):\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        self.image_paths = image_paths\n",
        "        self.target_img_paths = mask_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target_img_paths) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        i = index * self.batch_size\n",
        "        batch_input_img_paths = self.image_paths[i : i + self.batch_size]\n",
        "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
        "        x = np.zeros((self.batch_size,) + self.image_size + (3,), dtype=\"float32\")\n",
        "        for j, path in enumerate(batch_input_img_paths):\n",
        "            img = load_img(path, target_size=self.image_size)\n",
        "            x[j] = img\n",
        "        x = x / 255\n",
        "        y = np.zeros((self.batch_size,) + self.image_size + (1,), dtype=\"float32\")\n",
        "        for j, path in enumerate(batch_target_img_paths):\n",
        "            img = load_img(path, target_size=self.image_size, color_mode=\"grayscale\")\n",
        "            y[j] = (np.expand_dims(img, 2))\n",
        "        y = y / 255\n",
        "        return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaVXnO8F5Y7U"
      },
      "source": [
        "# Develop and Train Model\n",
        "This section builds the machine learning model that will automatically predict a segmentation mask over the provided endoscopy image. A neural network is structured as a series of layers, where inputs are passed through one end, and the output is produced in the other. Each layer has a series of nodes with a weight attached. The input passes through each of these nodes and is multiplied with the weights to produce the output. Below is an image of a simple neural network that takes two inputs and produces one output.\n",
        "\n",
        "![nn](https://upload.wikimedia.org/wikipedia/commons/3/3d/Neural_network.svg)\n",
        "\n",
        "Although our segmentation task may sound a bit more difficult, the principles are exactly the same. In our case, the image pixels are the input, and the output is a segmentation mask. However, this can get a bit complicated, so don't worry if you do not understand everything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TBVzko9eCoj"
      },
      "source": [
        "## Define Hyperparamters\n",
        "Before we start implementing the model, we first define a series of hyperparameters used for both the model implementation and training. Hyperparameters are parameters used to configure the training process of the neural network. They control things like how long to train, how many samples should be loaded at once, and how fast we should update the neural network's weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYT43aCLVVHH"
      },
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "loss_function = \"binary_crossentropy\"\n",
        "number_of_epochs = 5\n",
        "batch_size = 16\n",
        "image_size = (224, 224)\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"model_checkpoint.h5\", save_best_only=True)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS1m-Y1c7A-G"
      },
      "source": [
        "## Implement model\n",
        "In the function below, we implement a neural network that uses a popular architecture called U-Net, which is probably the most commonly used architecture for image segmentation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZWqDR777Ajl"
      },
      "source": [
        "def unet_model(img_size, num_classes=1):\n",
        "    inputs = keras.Input(shape=img_size + (3,))\n",
        "    x = keras.layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x\n",
        "\n",
        "    for filters in [64, 128, 256]:\n",
        "        x = keras.layers.Activation(\"relu\")(x)\n",
        "        x = keras.layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "        x = keras.layers.Activation(\"relu\")(x)\n",
        "        x = keras.layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "        x = keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        residual = keras.layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = keras.layers.add([x, residual])\n",
        "        previous_block_activation = x \n",
        "\n",
        "    for filters in [256, 128, 64, 32]:\n",
        "        x = keras.layers.Activation(\"relu\")(x)\n",
        "        x = keras.layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "        x = keras.layers.Activation(\"relu\")(x)\n",
        "        x = keras.layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "        x = keras.layers.UpSampling2D(2)(x)\n",
        "\n",
        "        residual = keras.layers.UpSampling2D(2)(previous_block_activation)\n",
        "        residual = keras.layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = keras.layers.add([x, residual])  \n",
        "        previous_block_activation = x \n",
        "\n",
        "    outputs = keras.layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eFr8AE3eIpQ"
      },
      "source": [
        "## Model Training\n",
        "Now that we have a function for loading data and building the model, we can put the pieces together and start training. Training is a trial and error process where we pass some data through the model, make a prediction, and tell the model how wrong it is. Using the measurement of how incorrect the prediction was, we can update the neural network's weights so that next time it may perform a bit better. This is done several hundred, thousands, or millions of times until the model reaches some convergence point.\n",
        "\n",
        "We begin by initializing the data loaders we defined earlier, one for training and one for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDfNjVUXXTha"
      },
      "source": [
        "training_data_loader = KvasirSEGDataLoader(batch_size, image_size, x_train, y_train)\n",
        "validation_data_loader = KvasirSEGDataLoader(batch_size, image_size, x_valid, y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiRFnIgYj0Z6"
      },
      "source": [
        "Here we initialize the model using the above model function, where we also define the size of the image that we plan to insert. Machine learning models require uniform input sizes, and we do not want them to be too big as it will drastically slow down training time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c5Hpt2576za"
      },
      "source": [
        "model = unet_model(image_size, num_classes=1)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9V_p3Kf7pgP"
      },
      "source": [
        "Now we are finally at the step of training the model. The code snippet below trains the model using the hyperparameters defined earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0hV1OqbT1ih"
      },
      "source": [
        "model.compile(optimizer=optimizer, loss=loss_function)\n",
        "model.fit(training_data_loader, epochs=number_of_epochs, validation_data=validation_data_loader, callbacks=callbacks)\n",
        "model.save(\"model_final.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31sWtlwFYuQM"
      },
      "source": [
        "The training process can be really slow. So to speed up the process, we can load the weights of a previously trained model so that we do not have to perform the training process every time we want to run the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cUNjyk20SND"
      },
      "source": [
        "!wget -O model.h5 https://www.dropbox.com/s/yh1545rn9sg3rtd/model.h5?dl=1\n",
        "model = keras.models.load_model(os.path.join(os.path.abspath(os.sep), \"content\", \"model.h5\"))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exj3DUDtYkII"
      },
      "source": [
        "# Model Evaluation and Testing\n",
        "Now that the model is finished training, it's time to verify that it works as expected. We do this by evaluating the model on the previously defined testing dataset. But first, let's look at some of the predictions our model is making."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXc2_DbU-iVa"
      },
      "source": [
        "\n",
        "test_data_loader = KvasirSEGDataLoader(1, image_size, x_test, y_test)\n",
        "\n",
        "for index in range(5, 10):\n",
        "\n",
        "    test_image, test_mask = test_data_loader[index]\n",
        "\n",
        "    pred_mask = model.predict(test_image)\n",
        "    test_image = test_image * 255\n",
        "\n",
        "    test_image = Image.fromarray(test_image.squeeze().astype(\"uint8\"))\n",
        "    test_mask = Image.fromarray(test_mask.squeeze() > .5)\n",
        "    pred_mask = Image.fromarray(pred_mask.squeeze() > .5)\n",
        "\n",
        "    show_images([test_image, test_mask, pred_mask], columns=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwPyMMv-5ZMr"
      },
      "source": [
        "These predictions look ok but let's get a general sense of how our model performs across the entire testing dataset. To do this, we define a variety of different metrics that should give us an idea of how the model performs.\n",
        "\n",
        "The metrics we will use are as follows:\n",
        "\n",
        "![pixel_privacy](https://stevenhicks.xyz/static/pixel_accuracy.png)\n",
        "\n",
        "The pixel accuracy is calculated by treating each pixel in the image as a binary classification mask and computing the accuracy from the results. In the equation above, TP is the true positives, TN is the true negatives, FP is the false positives, and FN is the false negatives for the pixel classification. The pixel accuracy ranges from 0 to 1, where 1 represents a perfect segmentation.\n",
        "\n",
        "![precision](https://stevenhicks.xyz/static/precision.png)\n",
        "\n",
        "The precision denotes the proportion of pixels that are correctly segmented positive (white) pixels against all positive pixels. The precision ranges from 0 to 1, where 1 means that the whole region containing the polyp was correctly segmented, and 0 denotes the opposite.\n",
        "\n",
        "![recall](https://stevenhicks.xyz/static/recall.png)\n",
        "\n",
        "The recall is similar to the precision but is calculated based on the ratio of pixels that are correctly segmented positive (white) pixels against all correctly segmented pixels. The recall is bounded between 0 and 1, where 1 represents perfectly segmenting the polyp, and 0 would be missing the polyp completely. \n",
        "\n",
        "![dice](https://stevenhicks.xyz/static/dice.png)\n",
        "\n",
        "The Sørensen–Dice coefficient, also called just the Dice coefficient or F1 Score, is a similarity metric used to gauge the similarity between two samples A and B. The metric ranges from 0 to 1, where 0 means the two samples are completely different, and 1 means that they are the same.\n",
        "\n",
        "![iou](https://stevenhicks.xyz/static/iou.png)\n",
        "\n",
        "The Intersection over Union (IoU), also called the Jaccard index, is similar to the Dice score and measures the similarity between two samples. Like Dice, the IoU score ranges from 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX_-C5xn5w4Q"
      },
      "source": [
        "def process_mask(mask):\n",
        "    mask = mask > 0.5\n",
        "    mask = mask.astype(np.uint8)\n",
        "    mask = mask.reshape(-1)\n",
        "    return mask\n",
        "\n",
        "CSV_VAL_ORDER = [\"Accuracy\", \"Jaccard\", \"Dice\", \"Recall\", \"Precision\"]    \n",
        "all_metrics = []\n",
        "\n",
        "for test_image, test_mask in test_data_loader:\n",
        "    \n",
        "    pred_mask = model.predict(test_image)\n",
        "\n",
        "    y_pred = process_mask(pred_mask)\n",
        "    y_true = process_mask(test_mask)\n",
        "    \n",
        "    score_accuracy = metrics.accuracy_score(y_true, y_pred)\n",
        "    score_jaccard = metrics.jaccard_score(y_true, y_pred, average=\"binary\")\n",
        "    score_dice = metrics.f1_score(y_true, y_pred, average=\"binary\")\n",
        "    score_recall = metrics.recall_score(y_true, y_pred, average=\"binary\")\n",
        "    score_precision = metrics.precision_score(y_true, y_pred, average=\"binary\", zero_division=0)\n",
        "\n",
        "    all_metrics.append([score_accuracy, score_jaccard, score_dice, score_recall, score_precision])\n",
        "\n",
        "mean_score = np.mean(all_metrics, axis=0)\n",
        "print(\"\\n\".join([\"%s: %0.4f\" % (header, score) for header, score in zip(CSV_VAL_ORDER, mean_score)]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}